{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fcc1ce8-cea2-4ed6-ad4b-600c4ba355f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 12:28:24.246970: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-28 12:28:24.250287: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-28 12:28:24.287838: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-28 12:28:25.100559: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1b3a108-7aa7-41d8-afd4-7c226f2c9dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Training Data\n",
    "train_dir = './dataset/sd04/train/'\n",
    "train_labels = []\n",
    "train_img_names = []\n",
    "train_img_paths = []\n",
    "train_gender = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(train_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(subdir, file), 'r') as t:\n",
    "                content = t.readlines()\n",
    "                train_gender.append(content[0].rsplit(' ')[1][0])\n",
    "                img_name = content[2].rsplit(' ')[1][:-4] + '.png'\n",
    "                train_img_paths.append(os.path.join(subdir, img_name))\n",
    "                train_img_names.append(img_name)\n",
    "                train_labels.append((content[1].rsplit(' ')[1][0]))           \n",
    "train_df = pd.DataFrame()\n",
    "train_df['IMAGE PATH'] = train_img_paths\n",
    "train_df['IMAGE NAME'] = train_img_names\n",
    "train_df['LABEL'] = train_labels\n",
    "train_df['GENDER'] = train_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6866dd27-5c94-4c56-996d-872a354d3716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Test Data\n",
    "test_dir = './dataset/sd04/test/'\n",
    "test_labels = []\n",
    "test_img_names = []\n",
    "test_img_paths = []\n",
    "test_gender = []\n",
    "\n",
    "for subdir, dirs, files in os.walk(test_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.txt'):\n",
    "            with open(os.path.join(subdir, file), 'r') as t:\n",
    "                content = t.readlines()\n",
    "                test_gender.append(content[0].rsplit(' ')[1][0])\n",
    "                img_name = content[2].rsplit(' ')[1][:-4] + '.png'\n",
    "                test_img_paths.append(os.path.join(subdir, img_name))\n",
    "                test_img_names.append(img_name)\n",
    "                test_labels.append((content[1].rsplit(' ')[1][0]))           \n",
    "test_df = pd.DataFrame()\n",
    "test_df['IMAGE PATH'] = test_img_paths\n",
    "test_df['IMAGE NAME'] = test_img_names\n",
    "test_df['LABEL'] = test_labels\n",
    "test_df['GENDER'] = test_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c915cb5-e111-47af-8da9-bc37ae03814a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(columns = 'GENDER',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c684261-c8d0-4e13-8ffd-a515f4fd0da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes = list(np.unique(train_labels))\n",
    "test_classes = list(np.unique(test_labels))\n",
    "train_map_classes = dict(zip(train_classes, [t for t in range(len(train_classes))]))\n",
    "test_map_classes = dict(zip(test_classes, [t for t in range(len(test_classes))]))\n",
    "train_df['MAPPED LABELS'] = [train_map_classes[i] for i in train_df['LABEL']]\n",
    "test_df['MAPPED LABELS'] = [test_map_classes[i] for i in test_df['LABEL']]\n",
    "train_df = train_df.sample(frac = 1) #To randomly shuffle the data\n",
    "test_df = test_df.sample(frac = 1) #To randomly shuffle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f75255-9298-41b3-a746-2316a2ebb9dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Creating numpy arrays of images\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m X_train_images \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m X_test_images \u001b[38;5;241m=\u001b[39m preprocess_input(np\u001b[38;5;241m.\u001b[39marray(X_test_images, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Convert labels to one-hot format\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/auth/lab4/lab4_jupyter/lib/python3.10/site-packages/keras/src/applications/resnet.py:504\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[0;34m(x, data_format)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;129m@keras_export\u001b[39m(\n\u001b[1;32m    498\u001b[0m     [\n\u001b[1;32m    499\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.applications.resnet50.preprocess_input\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    502\u001b[0m )\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_input\u001b[39m(x, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimagenet_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_input\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcaffe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/auth/lab4/lab4_jupyter/lib/python3.10/site-packages/keras/src/applications/imagenet_utils.py:104\u001b[0m, in \u001b[0;36mpreprocess_input\u001b[0;34m(x, data_format, mode)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected data_format to be one of `channels_first` or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`channels_last`. Received: data_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_preprocess_numpy_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _preprocess_tensor_input(x, data_format\u001b[38;5;241m=\u001b[39mdata_format, mode\u001b[38;5;241m=\u001b[39mmode)\n",
      "File \u001b[0;32m~/Desktop/auth/lab4/lab4_jupyter/lib/python3.10/site-packages/keras/src/applications/imagenet_utils.py:224\u001b[0m, in \u001b[0;36m_preprocess_numpy_input\u001b[0;34m(x, data_format, mode)\u001b[0m\n\u001b[1;32m    222\u001b[0m             x[:, \u001b[38;5;241m2\u001b[39m, :, :] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m std[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 224\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m mean[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    225\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m mean[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    226\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m mean[\u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "X_train = train_df['IMAGE PATH']\n",
    "y_train = train_df['MAPPED LABELS']\n",
    "X_test = test_df['IMAGE PATH']\n",
    "y_test = test_df['MAPPED LABELS']\n",
    "\n",
    "# Define image size\n",
    "img_size = (224, 224)  # Resize all images to (224, 224)\n",
    "\n",
    "# Creating numpy arrays of images\n",
    "X_train_images = []\n",
    "X_test_images = []\n",
    "for filename in X_train:\n",
    "    img=cv2.imread(filename)\n",
    "    try:\n",
    "        img = cv2.resize(img, img_size, interpolation=cv2.INTER_AREA)\n",
    "        height, width , layers = img.shape\n",
    "        X_train_images.append(img)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "for filename in X_test:\n",
    "    img=cv2.imread(filename)\n",
    "    try:\n",
    "        img = cv2.resize(img, img_size, interpolation=cv2.INTER_AREA)\n",
    "        height, width , layers = img.shape\n",
    "        size=(width,height)\n",
    "        X_test_images.append(img)\n",
    "    except:\n",
    "        print(\"asfasfaf\")\n",
    "        continue\n",
    "# Creating numpy arrays of images\n",
    "X_train_images = preprocess_input(np.array(X_train_images, dtype=float))\n",
    "X_test_images = preprocess_input(np.array(X_test_images, dtype=float))\n",
    "\n",
    "# Convert labels to one-hot format\n",
    "y_train_one_hot = keras.utils.to_categorical(y_train, num_classes=5)\n",
    "y_test_one_hot = keras.utils.to_categorical(y_test, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286d95d-b433-4c71-9179-0ec39dc47683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained ResNet50 model without the top classification layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the weights of the pre-trained layers so they are not updated during training\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Fine-Tuning\n",
    "for layer in base_model.layers[-10:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Data Augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow(X_train_images, y_train_one_hot, batch_size=64)\n",
    "\n",
    "# Add Dropout to the classification head\n",
    "x = base_model.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = keras.layers.Dropout(0.5)(x)  # Add dropout\n",
    "predictions = keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Learning Rate Scheduler\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, min_lr=0.00001)\n",
    "\n",
    "# Compile the model with regularization\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add early stopping\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with data augmentation and regularization\n",
    "history = model.fit(train_generator, epochs=20, validation_data=(X_test_images, y_test_one_hot), callbacks=[lr_scheduler, early_stopping], verbose=1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_images, y_test_one_hot)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f84f61e-c947-4124-8648-4d89d43637cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8f2ef0-55a6-4d5a-86da-e4301d603ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
